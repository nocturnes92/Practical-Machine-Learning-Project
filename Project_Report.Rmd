---
title: "Practical Machine Learning Project"
author: "Yigang"
output:
  pdf_document: default
  html_document:
    keep_md: yes
---

# Introduction 

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.The goal of this project is to predict the manner in which they did the exercise by using the data collected by Human Activity Recognition project. 

# Data Processing

## Getting and Cleaning Data

### Download and Read the Data
```{r}
# Globe environment setting
library(lattice)
library(ggplot2)
library(ggcorrplot)
library(caret)
library(rattle)
library(rpart)
library(rpart.plot)
library(corrplot)
knitr::opts_chunk$set(warning=FALSE, message=FALSE)

# Import data sets
TrainUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
TestUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
RawTrainData <- read.csv(url(TrainUrl), header = TRUE)
RawTestData <- read.csv(url(TestUrl), header = TRUE)
```

### Clean the Data

- Notice there are missing values in the data set, and variables provides information of observations but not for prediction, so we will neglect these data. 
```{r}
# See how many missing values in the data set
sum(complete.cases(RawTrainData))
sum(complete.cases(RawTestData))

# Remove all columns that contain missing values
TrainData <- RawTrainData[, colSums(is.na(RawTrainData)) == 0]
TestData <- RawTestData[, colSums(is.na(RawTestData)) == 0]
 
# Remove columns records users' names, timestamps and etc.
TrainData <- TrainData[, -c(1:7)]
TestData <- TestData[, -c(1:7)]
```

## Preprocessing Data

### Slice the Data
- Split the training data into a training data set and a validation data set for the cross validation.

```{R}
# Set 30% of data from training data to be used for validation
# The "classe" variable in the training set is the manner in which users did the exercise
set.seed(1234)
partition <- createDataPartition(TrainData$classe, p=0.75, list=FALSE)
TrainData <- TrainData[partition,]
ValiData <- TrainData[-partition,]
```

## Modeling Data with Different Algorithms

We plan to use following methods to train and predict the data:
- Classification Trees
- Random Forests
- Generalized Boosted Model

### Classification Trees Method

- Training
```{R}
# Train data through classification tree method
Model_CT <- rpart(classe ~ ., data = TrainData, method="class")

# Check the statistical result 
Model_CT

# Show tree by using fancyRpartPlot function
fancyRpartPlot(Model_CT$finalModel)

```

- Validating

```{R}
# Predict validation data with the model trained
Pred_CT <- predict(Model_CT, ValiData, type = "class")

# See the accuracy of the prediction
confmat_CT <- confusionMatrix(Pred_CT, factor(ValiData$classe))
confmat_CT
```

- Here we get a very low prediction accuracy with the classification tree method, so we need to try other ways.

### Random Forests Method

- Training

```{R}
# Set k=5 in k-fold cross validation
control_RF <- trainControl(method="cv", number=5, verboseIter=FALSE)

# Train data through random forests method
Model_RT <- train(classe ~ ., data = TrainData, method = "rf", trControl = control_RF)

# Check the statistical result 
Model_RT
```

- Validating

```{R}
# Predict validation data with the model trained 
Pred_RF <- predict(Model_RF, ValiData)

# See the accuracy of the prediction
confmat_RF <- confusionMatrix(Pred_RF, factor(ValiData$classe))
confmat_RF
```

- Here we get really good prediction accuracy with the random forests method, so we want to have a deeper view of this model.

```{R}
# A plot of number of trees versus error of model
plot(Model_RF$finalModel)

# See the importance of each variables in this model
varImp(model_RF)
```

### Generalized Boosted Method

- Training 

```{R}
# Set seed for reproduce
set.seed(1233)
control_GBM <- trainControl(method = "repeatedcv", number = 5, repeats = 1)

# Train data through random forests method
Model_GBM <- train(classe ~ ., data = TrainData, method = "gbm",
                   trControl = control_GBM, verbose = FALSE)

# Check the statistical result 
Model_GBM
```

- Validating

```{R}
# Predict validation data with the model trained 
Pred_GBM <- predict(Model_GBM, ValiData)

# See the accuracy of the prediction
confmat_GBM <- confusionMatrix(Pred_GBM, factor(ValiData$classe))
confmat_GBM
```

- Here we also get good prediction accuracy with the Generalized Boosted method, so again we want to explore this model.

```{R}
# An Boosting Iterations versus accuracy plot
plot(Model_GBM)
```

# Conclusion

- Classification Trees Model is no a suitable model for this data set.
- Random Forests Model has the best prediction accuracy, so we will apply it to predict  ``` TestData```. 
- Generalized Boosted Model also has a high prediction accuracy, which is just a little bit lower than Random Forests Model's, and it may be an alternate option in the future.

## Apply Random Forests Model to the Test Set 

```{R}
TestPred <- predict(Model_RF, TestData)
TestPred
```

